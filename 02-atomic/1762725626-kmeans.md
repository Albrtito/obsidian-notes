---
aliases:
- k-means
tags:
- ms
---
# k-means
> [!info] Intro: 
> K-Means is a [[1762722095-partitionalclustering|partitional clustering]] method that uses **heuristics**. 
> Each cluster is represented by the center of the cluster, the center of the cluster is given by **the mean**
> K needs to be defined and representes the **number of clusters**

>[!example]- Dictionary:
> - **centroid->** Each cluster center


>[!attention] Remarks:
> - Distances can be calculated however, although it is usually the **euclidean distance**

1. Initialize randomly k centsers (start somewhere) Would make more sense if the clusters are far appart.
2. Repeat until cluster centers do not change anymore or some number of repetitions.
	1. What points are closer to the cluster centers? Assign them to that cluster
	2. Change the centroid to the mean point of the points it represents
The cluster update (mean of all points it represents) can be mathematically represented as:
$$
c_{k} = \frac{\sum_{n} u_{n,k}\cdot x_{n}}{\sum_{n}u_{n,k}}
$$
**where:**
 - $u_{n,k}$ -> Is 0 if the point x_n is not in the cluster, 1 if it is. (only add the ones we want for each centroid)

## weaknesses and strenghts:

**Pros:**
- Super simple
- Really efficient

**Cons:**
- Problems with categoriacal data (needs numerical data)
- Needs a k (number of clusters)
- Problems with noise and sensitive to outliers
- Non suitable to discover clusters with non-convex shapes (banana)
***
### Up
- [[1762722095-partitionalclustering|partitional clustering]]
### Down
***